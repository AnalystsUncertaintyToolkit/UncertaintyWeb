#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library(fdrtool)
library(ddpcr)
library(knitr)
library(tidyverse) #allows use of multiple functions whilst running model
library(BNPdensity)
setwd("~/FSM model SW local/FSM volumes model SW local/")
# Create R file from Master_Control Markdown file
purl("Master_Control.Rmd", output="Master_Control.R")
# source data functions ---------------------------------------------------
source("Model/Uncertainty Development/get_unemployment_data_function.R")
source("Model/Uncertainty Development/get_regression_data_function.R")
source("Model/Uncertainty Development/get_NPP_data_function.R")
# percentiles of uncertainty variables ------------------------------------
# percentile values to pick out for uncertainty variables
regression_percentiles <-c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
unem_percentiles<- c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
NPP_percentiles <-c(0.1,0.3,0.5,0.7,0.9)
# MC loop -----------------------------------------------------------------
# keep track of run number with variable
run_num <- 0
for (unemployment_percentile in unem_percentiles){
for (regression_percentile in regression_percentiles){
for (NPP_percentile in NPP_percentiles){
# increase run_num for each run
run_num = run_num + 1
# START TIME
start_time<-Sys.time()
# generate pseudo random data for MC run -----------------------------------------
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile)
# generate unemployment data sample
get_unemployment_data(unemployment_sample)
# get regression sample for percentile value
# sample from normal distribution with mean 0 and sd 1
regression_sample = qnorm(regression_percentile)
# the regression data function is in model (step 1a. Modify regression input data)
# this is because the regression data is produced in the model
# get NPP sample for percentile value
# sample from normal distribution with mean 0 and sd 1
NPP_sample = qnorm(NPP_percentile)
# generate NPP data sample
get_NPP_data(NPP_sample)
# Run model ---------------------------------------------------------------
# use custom function to run code in R markdown file
#quiet(source("Master_Control.R"))
# END TIME
end_time <- Sys.time()
# TIME TAKEN for run
print(run_num)
print(end_time - start_time)
}
}
}
# process outputs ---------------------------------------------------------
#source("Model/Model_outputs/get_5th_95th_percentiles_from_MC_output.R")
getwd()
setwd("C:/Users/SWALSH1/FSM volumes model SW local")
# function to run Monte Carlo on model
#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library(fdrtool)
library(ddpcr)
library(knitr)
library(tidyverse) #allows use of multiple functions whilst running model
library(BNPdensity)
setwd("~/FSM model SW local/FSM volumes model SW local/")
# Create R file from Master_Control Markdown file
purl("Master_Control.Rmd", output="Master_Control.R")
# source data functions ---------------------------------------------------
source("Model/Uncertainty Development/get_unemployment_data_function.R")
source("Model/Uncertainty Development/get_regression_data_function.R")
source("Model/Uncertainty Development/get_NPP_data_function.R")
# percentiles of uncertainty variables ------------------------------------
# percentile values to pick out for uncertainty variables
regression_percentiles <-c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
unem_percentiles<- c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
NPP_percentiles <-c(0.1,0.3,0.5,0.7,0.9)
# MC loop -----------------------------------------------------------------
# keep track of run number with variable
run_num <- 0
for (unemployment_percentile in unem_percentiles){
for (regression_percentile in regression_percentiles){
for (NPP_percentile in NPP_percentiles){
# increase run_num for each run
run_num = run_num + 1
# START TIME
start_time<-Sys.time()
# generate pseudo random data for MC run -----------------------------------------
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile)
# generate unemployment data sample
get_unemployment_data(unemployment_sample)
# get regression sample for percentile value
# sample from normal distribution with mean 0 and sd 1
regression_sample = qnorm(regression_percentile)
# the regression data function is in model (step 1a. Modify regression input data)
# this is because the regression data is produced in the model
# get NPP sample for percentile value
# sample from normal distribution with mean 0 and sd 1
NPP_sample = qnorm(NPP_percentile)
# generate NPP data sample
get_NPP_data(NPP_sample)
# Run model ---------------------------------------------------------------
# use custom function to run code in R markdown file
#quiet(source("Master_Control.R"))
# END TIME
end_time <- Sys.time()
# TIME TAKEN for run
print(run_num)
print(end_time - start_time)
}
}
}
# process outputs ---------------------------------------------------------
#source("Model/Model_outputs/get_5th_95th_percentiles_from_MC_output.R")
# function to run Monte Carlo on model
#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library(fdrtool)
library(ddpcr)
library(knitr)
library(tidyverse) #allows use of multiple functions whilst running model
library(BNPdensity)
setwd("C:/Users/SWALSH1/FSM volumes model SW local/)
# Create R file from Master_Control Markdown file
purl("Master_Control.Rmd", output="Master_Control.R")
# source data functions ---------------------------------------------------
source("Model/Uncertainty Development/get_unemployment_data_function.R")
source("Model/Uncertainty Development/get_regression_data_function.R")
source("Model/Uncertainty Development/get_NPP_data_function.R")
# percentiles of uncertainty variables ------------------------------------
# percentile values to pick out for uncertainty variables
regression_percentiles <-c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
unem_percentiles<- c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
NPP_percentiles <-c(0.1,0.3,0.5,0.7,0.9)
# MC loop -----------------------------------------------------------------
# keep track of run number with variable
run_num <- 0
for (unemployment_percentile in unem_percentiles){
for (regression_percentile in regression_percentiles){
for (NPP_percentile in NPP_percentiles){
# increase run_num for each run
run_num = run_num + 1
# START TIME
start_time<-Sys.time()
# generate pseudo random data for MC run -----------------------------------------
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile)
# generate unemployment data sample
get_unemployment_data(unemployment_sample)
# get regression sample for percentile value
# sample from normal distribution with mean 0 and sd 1
regression_sample = qnorm(regression_percentile)
# the regression data function is in model (step 1a. Modify regression input data)
# this is because the regression data is produced in the model
# get NPP sample for percentile value
# sample from normal distribution with mean 0 and sd 1
NPP_sample = qnorm(NPP_percentile)
# generate NPP data sample
get_NPP_data(NPP_sample)
# Run model ---------------------------------------------------------------
# use custom function to run code in R markdown file
#quiet(source("Master_Control.R"))
# END TIME
end_time <- Sys.time()
# TIME TAKEN for run
print(run_num)
print(end_time - start_time)
}
}
}
# process outputs ---------------------------------------------------------
#source("Model/Model_outputs/get_5th_95th_percentiles_from_MC_output.R")
# function to run Monte Carlo on model
#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library(fdrtool)
library(ddpcr)
library(knitr)
library(tidyverse) #allows use of multiple functions whilst running model
library(BNPdensity)
setwd("C:/Users/SWALSH1/FSM volumes model SW local/")
# Create R file from Master_Control Markdown file
purl("Master_Control.Rmd", output="Master_Control.R")
# source data functions ---------------------------------------------------
source("Model/Uncertainty Development/get_unemployment_data_function.R")
source("Model/Uncertainty Development/get_regression_data_function.R")
source("Model/Uncertainty Development/get_NPP_data_function.R")
# percentiles of uncertainty variables ------------------------------------
# percentile values to pick out for uncertainty variables
regression_percentiles <-c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
unem_percentiles<- c(0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95)
NPP_percentiles <-c(0.1,0.3,0.5,0.7,0.9)
# MC loop -----------------------------------------------------------------
# keep track of run number with variable
run_num <- 0
for (unemployment_percentile in unem_percentiles){
for (regression_percentile in regression_percentiles){
for (NPP_percentile in NPP_percentiles){
# increase run_num for each run
run_num = run_num + 1
# START TIME
start_time<-Sys.time()
# generate pseudo random data for MC run -----------------------------------------
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile)
# generate unemployment data sample
get_unemployment_data(unemployment_sample)
# get regression sample for percentile value
# sample from normal distribution with mean 0 and sd 1
regression_sample = qnorm(regression_percentile)
# the regression data function is in model (step 1a. Modify regression input data)
# this is because the regression data is produced in the model
# get NPP sample for percentile value
# sample from normal distribution with mean 0 and sd 1
NPP_sample = qnorm(NPP_percentile)
# generate NPP data sample
get_NPP_data(NPP_sample)
# Run model ---------------------------------------------------------------
# use custom function to run code in R markdown file
#quiet(source("Master_Control.R"))
# END TIME
end_time <- Sys.time()
# TIME TAKEN for run
print(run_num)
print(end_time - start_time)
}
}
}
# process outputs ---------------------------------------------------------
#source("Model/Model_outputs/get_5th_95th_percentiles_from_MC_output.R")
library(BNPdensity)
?qhalfnorm
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile)
# get unemployment sample for percentile value
# sample from half normal distribution with mean 0 and sd 1
unemployment_sample = qhalfnorm(unemployment_percentile, mean =0, sd =1)
#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library(fdrtool)
?qhalfnorm
#############################################################################
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# MAKE SURE MC_RUN VARIABLE IS SET TO ONE IN Master_Control R MARKDOWN FILE
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#############################################################################
library("fdrtool")
?qhalfnorm
?qhalfnorm {fdrtool}
?rhalfnorm
?dhalfnorm
qhalfnorm(1)
??qhalfnorm
?qhalfnorm
??qhalfnorm
detach("package:BNPdensity", unload=TRUE)
?qhalfnorm
?message
?ref.label
??fig.cap
## Firstly, ensure that your One Drive is synced to the following:
# "https://educationgovuk.sharepoint.com/sites/FPUandESFA-BudgetandSpend/Schools Pension Grant/"
## set up directory
user_name = Sys.getenv("USERNAME")
setwd(file.path("C:/Users/",user_name,"/Department for Education/FPU and ESFA - Budget and Spend - Schools' Pension Grant/Modelling/Supp_Fund_update"))
## load required libraries
library("readxl") # allows us to read xlsx files
library("tidyverse") # read CSVs, run pipe operations
## 1) policy inputs & other constants
income_pc_thresh = 0.0005 # 0.05% of income threshold
NI_cont = 0.1045 # 10.45% weighted avg pension ontribution from cell L25 from Data\SchoolStaffNI_190618.xlsx
old_pension_cont = 0.164 # 16.4% previous pension contribution
new_pension_cont = 0.236 # 23.6% new pension contribution
wapa_1819 = 0.024 # The weighted average pay award from the September of AY2018/19 was 2.4%.
wapa_1920 = 0.0275 # The weighted average pay award from the September of AY2019/20 is 2.75%.
grant_months = 7 # to reflect the Sept-Mar month count - which is the grant length
year_months = 12
## 2) Import data
# import APT data provided by Graeme - this contains school income data
school_income_data_raw = read_csv("Data/school_income_data.csv")
# pensions allocations for 19/20 from work in Oct-19 \\Lonnetapp01\asddata\SARC\Teachers Pension Grant\2019-20\Models\Jon
pensions_grant_raw = read_csv("Data/all_alloc_v2.csv")
# import teacher salary from latest AAR (1718AY) / CFR (1819FY)
acad_1718_raw <- read_excel("Data/SFB_Academies_2017-18_download.xlsx",sheet = "Academies 2017 to 18")
LAM_1819_raw = read_excel("Data/School_total_spend_2018-19_Full_Data_Workbook.xlsx",sheet = "CFR Data")
LAM_1819_feds_raw = read_excel("Data/School_total_spend_2018-19_Full_Data_Workbook.xlsx",sheet = "Federations") # federations are groups of schools which we want to remove from the analysis because the pupil count shown against the "lead school" is for the whole federation but the income is not
## 3) clean and add useful columns to the raw data so that it can be meaningfully used
# school income data
# this is APT/GAG (pro-rated 7 months) plus rates estimate (pro-rated 7 months) plus TPG (Sept 19 to March 20 allocations)
school_income_data_clean = school_income_data_raw %>%
na.omit() %>% # remove the Holland Park Primary School entry which doesn't have a numerical input - have mentioned this to Graeme
select(URN,name = "Establishment Name",income = "Overall Budget Total") %>%
filter(income > 0) %>%  #The schools with ?0 are nursery schools.
mutate(income_thresh = income*income_pc_thresh) %>%
select(-income)
# pension grant data from recently published allocations - this includes specials as well as mainstream
pensions_grant_clean = pensions_grant_raw %>%
select(URN = URN_final, Name, grant_alloc = total_alloc2)
# AAR data
acad_Sep19_Mar20_pen_costs = acad_1718_raw %>%
filter(between(row_number(),3,nrow(acad_1718_raw))) %>% #filter out the top rows which aren't actual data
select(URN = names(acad_1718_raw)[4],
teacher_cnt = names(acad_1718_raw)[17],
teacher_sal = names(acad_1718_raw)[50]) %>%
transform(URN = as.numeric(URN),
teacher_cnt = as.numeric(teacher_cnt),
teacher_sal = as.numeric(teacher_sal)) %>%
distinct(URN,.keep_all = TRUE) %>% # remove duplicate URN rows. "distinct" function keeps only one
filter(teacher_cnt > 0, teacher_sal > 1) %>%  # teacher count should be >0, teacher salary should be greater than ?1!
na.omit() %>% # remove those with either no teacher numbers or no teacher salary
#now filter out some outliers which we assume as data errors, based on average teacher salaries
mutate(avg_teacher_salary = teacher_sal/teacher_cnt) %>%
filter(avg_teacher_salary >= quantile(avg_teacher_salary,0.05),avg_teacher_salary <= quantile(avg_teacher_salary,0.95)) %>%  # strip out outliers as some average salaries appear to be implausibly high or low
select(-avg_teacher_salary,-teacher_cnt) %>%
# need to get from Annual AAR AY1718 overall salary to the 7 months from Sep19-Mar20
mutate(teacher_sal_Sep19_Mar20 = (teacher_sal/year_months)*(1+wapa_1819)*(1+wapa_1920)*grant_months) %>% # The first bit for gets you to the monthly salary for AY17/18. It's fairly simple after this - you simply inflate for 18/19, then 19/20, then multiply up to the 7 months we are looking at from Sep19-Mar20.
select(-teacher_sal) %>%
#Now we have the 7 month salary for Sep19-Mar20, we need to work estimate the cost of pensions contribution increase
#We need to factor in that NI contribution is included in the salary figure too
mutate(sal_without_Pen_NI = teacher_sal_Sep19_Mar20/(1+NI_cont+old_pension_cont),
sal_with_newPen_NI = sal_without_Pen_NI*(1+NI_cont+new_pension_cont),
acad_pens_uplift_cost = sal_with_newPen_NI - teacher_sal_Sep19_Mar20) %>%
select(URN,acad_pens_uplift_cost)
# produce clean version of LAM 1819 federation URNs
LAM_1819_feds = LAM_1819_feds_raw %>%
filter(between(row_number(),4,nrow(LAM_1819_feds_raw))) %>% #filter out the top rows which aren't actual data
select(URN = names(LAM_1819_feds_raw)[3]) %>%
na.omit() %>%
transform(URN = as.numeric(URN)) %>% # numeric so can be joined to other data sets
mutate(fed_flag = 1) %>%
arrange(URN)
# CFR data
LAM_Sep19_Mar20_pen_costs = LAM_1819_raw %>%
filter(between(row_number(),4,nrow(LAM_1819_raw))) %>% #filter out the top rows which aren't actual data
select(URN = names(LAM_1819_raw)[7],
name = names(LAM_1819_raw)[8],
teacher_sal = names(LAM_1819_raw)[38]) %>%
transform(URN = as.numeric(URN),
teacher_sal = as.numeric(teacher_sal)) %>%
distinct(URN,.keep_all = TRUE) %>% # remove duplicate URN rows. "distinct" function keeps only one
filter(teacher_sal > 1) %>%  # teacher count should be >0
merge(LAM_1819_feds, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # join the FED flag dataset
filter(is.na(fed_flag)) %>% # we want to eliminate the FED flags - i.e. keep those that are "na"
select(-fed_flag) %>%
arrange(URN) %>%
# need to get from the Annual CFR FY1819 overall salary to the 7 months from Sep19-Mar20
mutate(teacher_sal_Sep19_Mar20 = (teacher_sal/((year_months-7)+(7*(1+wapa_1819))))*(1+wapa_1819)*(1+wapa_1920)*grant_months) %>% # The first bit for gets you to the monthly salary for AY17/18. It's fairly simple after this - you simply inflate for 18/19, then 19/20, then multiply up to the 7 months we are looking at from Sep19-Mar20.
select(-teacher_sal) %>%
#Now we have the 7 month salary for Sep19-Mar20, we need to work estimate the cost of pensions contribution increase
#We need to factor in that NI contribution is included in the salary figure too
mutate(sal_without_Pen_NI = teacher_sal_Sep19_Mar20/(1+NI_cont+old_pension_cont),
sal_with_newPen_NI = sal_without_Pen_NI*(1+NI_cont+new_pension_cont),
LAM_pens_uplift_cost = sal_with_newPen_NI - teacher_sal_Sep19_Mar20) %>%
select(URN,LAM_pens_uplift_cost)
## 5) join the data so we can make estimations of supp fund
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
SF_estimate_init = sum(mainstream_data_init$supp_fund) # this is an estimate including most mainstreams, no specials.
grant_alloc_init = sum(mainstream_data_init$grant_alloc)
# Let's assume that the cost of the SF for the missing institutes will be the same on average per ? of pension alloc as for those we have already estimated
SF_per_pound_pens_grant = SF_estimate_init/grant_alloc_init
# So now let's find out the grant for those institutes not included in this analysis
remaining_institutes = pensions_grant_clean %>%
merge(mainstream_data_init, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(missing = ifelse(is.na(supp_fund),1,0)) %>%
select(URN,Name,grant_alloc = "grant_alloc.x", missing) %>%
filter(missing == 1) # filter those for which we don't have a supp fund estimate
grant_alloc_missing = sum(remaining_institutes$grant_alloc)
SF_estimate_missing = SF_per_pound_pens_grant*grant_alloc_missing
SF_estimate_total = SF_estimate_init + SF_estimate_missing
SF_estimate_total
View(remaining_institutes)
remaining_institutes = pensions_grant_clean %>%
merge(mainstream_data_init, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(missing = ifelse(is.na(supp_fund),1,0))
View(pensions_grant_clean)
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
#select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
View(mainstream_data_init)
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
#select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
#select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE)
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE)
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1))
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
SF_estimate_init = sum(mainstream_data_init$supp_fund) # this is an estimate including most mainstreams, no specials.
grant_alloc_init = sum(mainstream_data_init$grant_alloc)
# Let's assume that the cost of the SF for the missing institutes will be the same on average per ? of pension alloc as for those we have already estimated
SF_per_pound_pens_grant = SF_estimate_init/grant_alloc_init
# So now let's find out the grant for those institutes not included in this analysis
remaining_institutes = pensions_grant_clean %>%
merge(mainstream_data_init, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(missing = ifelse(is.na(supp_fund),1,0)) %>%
select(URN,Name,grant_alloc = "grant_alloc.x", missing) %>%
filter(missing == 1) # filter those for which we don't have a supp fund estimate
grant_alloc_missing = sum(remaining_institutes$grant_alloc)
SF_estimate_missing = SF_per_pound_pens_grant*grant_alloc_missing
SF_estimate_total = SF_estimate_init + SF_estimate_missing
SF_estimate_total
View(remaining_institutes)
mainstream_data_init = school_income_data_clean %>%
merge(pensions_grant_clean, by.x = "URN", by.y = "URN", all.x = TRUE) %>% # keep all from school income data list as this is definitive
select(-Name) %>% # name is in twice so can remove the pensions grant version
merge(acad_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%  # keep all from school income data list as this is definitive
merge(LAM_Sep19_Mar20_pen_costs, by.x = "URN", by.y = "URN", all.x = TRUE) %>%
mutate(Sep19_Mar20_pen_flag = ifelse(is.na(acad_pens_uplift_cost)&is.na(LAM_pens_uplift_cost),0,1)) %>%  # find out which ones do (1) or don't (0) have pension cost increase estimates
filter(Sep19_Mar20_pen_flag == 1) %>% # include the ones for which we have pension cost increase estimates
replace(., is.na(.), 0) %>% # we do this as we need to add together in next line
mutate(Sep19_Mar20_pen_costs = acad_pens_uplift_cost + LAM_pens_uplift_cost) %>%
select(-acad_pens_uplift_cost, -LAM_pens_uplift_cost, -Sep19_Mar20_pen_flag ) %>%
# now calculate the cost to get to the 0.05% threshold, which is the difference between what the allocation would be based on rates and pupil numbers, and the expectation based on pension increases from 16.4 to 23.6%
mutate(supp_fund = ifelse(Sep19_Mar20_pen_costs - grant_alloc - income_thresh > 0,
Sep19_Mar20_pen_costs - grant_alloc - income_thresh, 0))
write_csv(mainstream_data_init,"mainstream_data_init.csv")
write_csv(remaining_institutes,"remaining_institutes.csv")
getwd()
SF_per_pound_pens_grant
install.packages("png")
install.packages("pdp")
warnings()
install.packages("pdp")
